
import { GoogleGenAI, Modality, GenerateContentResponse } from "@google/genai";
import { MockupType } from '../types';

const MODEL_NAME = 'gemini-2.5-flash-image';

const getPromptForType = (mockupType: MockupType): string => {
  const commonInstructions = `
**CRITICAL INSTRUCTION:**
The design's position, size, and aspect ratio in the input image are PRECISE. You MUST NOT change them. The final effect must appear exactly where the overlay is.

**PROCESS:**
1.  Identify the overlay design and the product (e.g., leather wallet, t-shirt, etc.) beneath it.
2.  Apply the specified effect realistically.
3.  The effect must perfectly match the product's lighting, shadows, and material grain.
4.  **Crucially, the design must conform to the product's surface geometry. If the product has folds, creases, or curves, the design must bend, warp, and distort naturally to follow those contours. This is essential for a realistic result.**
5.  Do not alter any other part of the image (product shape, background, etc.).
6.  Output ONLY the final, edited image.`;

  switch (mockupType) {
    case MockupType.PRINT:
      return `You are an AI image editing specialist. Your task is to convert the overlay design in the provided image into a photorealistic screen print on the product.

The design should look like it has been printed with high-quality ink. The colors of the original design MUST be preserved. The print should follow the texture of the material, showing subtle imperfections and interaction with the material's grain to make it look realistic.
${commonInstructions}`;
    case MockupType.EMBOSS:
      return `You are an AI image editing specialist. Your task is to convert the overlay design in the provided image into a photorealistic 'debossed' (pressed in) effect on the product.

The design should appear indented into the material, creating realistic depth with shadows and highlights that match the image's lighting. The color of the design should be the natural, darkened color of the pressed material, not the original design color.
${commonInstructions}`;
    case MockupType.ENGRAVE:
    default:
      return `You are an AI image editing specialist. Your task is to convert the overlay design in the provided image into a photorealistic laser engraving on the product.

Realistically "carve" the design into the material, giving it depth. The engraved area should appear slightly darkened or burnt, typical of laser engraving on materials like leather or wood.
${commonInstructions}`;
  }
}

export const generateMockup = async (compositeImageBase64: string, mockupType: MockupType): Promise<string> => {
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

  const prompt = getPromptForType(mockupType);

  // Remove the data URL prefix e.g. "data:image/jpeg;base64,"
  const base64Data = compositeImageBase64.split(',')[1];
  
  const imagePart = {
    inlineData: {
      data: base64Data,
      mimeType: 'image/jpeg',
    },
  };

  const textPart = {
    text: prompt,
  };

  try {
    const response: GenerateContentResponse = await ai.models.generateContent({
        model: MODEL_NAME,
        contents: {
          parts: [imagePart, textPart],
        },
        config: {
            responseModalities: [Modality.IMAGE],
        },
    });

    for (const part of response.candidates[0].content.parts) {
        if (part.inlineData) {
          const base64ImageBytes: string = part.inlineData.data;
          return `data:image/png;base64,${base64ImageBytes}`;
        }
    }
    
    throw new Error("No image was generated by the model.");

  } catch (error) {
    console.error("Error generating mockup with Gemini API:", error);
    // Re-throw the original error so the UI layer can inspect its message
    throw error;
  }
};
